apiVersion: apps/v1
kind: Deployment
metadata:
  name: llmserver
  namespace: default
  labels:
    app: llmserver
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llmserver
  template:
    metadata:
      labels:
        app: llmserver
      annotations:
        instrumentation.opentelemetry.io/inject-python: 'true'
    spec:
      containers:
      - name: llmpod
        image: acrrca123.azurecr.io/llmservice:latest # {"$imagepolicy": "flux-system:llmimagepol"}
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        # resources: # Task 2
        #   requests:
        #     cpu: "300m"
        # startupProbe:
        #   httpGet:
        #     path: /healthcheck
        #     port: 8080
        #   initialDelaySeconds: 60
        #   failureThreshold: 30
        #   periodSeconds: 20
        # readinessProbe:
        #   httpGet:
        #     path: /healthcheck
        #     port: 8080
        #   failureThreshold: 15
        #   periodSeconds: 30
